{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_Detection_Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2D0Kxh3iOybe3ucKOu9ga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skj092/Computer_Vision_Lab/blob/main/Mask_Detection_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57uDSFH8yyWn",
        "outputId": "69eeef4a-943a-4d30-92a0-1073bd02fd43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 175725, done.\u001b[K\n",
            "remote: Counting objects: 100% (8088/8088), done.\u001b[K\n",
            "remote: Compressing objects: 100% (572/572), done.\u001b[K\n",
            "remote: Total 175725 (delta 7594), reused 7944 (delta 7499), pack-reused 167637\u001b[K\n",
            "Receiving objects: 100% (175725/175725), 346.36 MiB | 31.53 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!pip install pycocotools --quiet\n",
        "!git clone https://github.com/pytorch/vision.git\n",
        "!git checkout v0.3.0\n",
        "\n",
        "!cp vision/references/detection/utils.py ./\n",
        "!cp vision/references/detection/transforms.py ./\n",
        "!cp vision/references/detection/coco_eval.py ./\n",
        "!cp vision/references/detection/engine.py ./\n",
        "!cp vision/references/detection/coco_utils.py ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade albumentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrx9ptEj0XkH",
        "outputId": "ea4f9d9f-4fd6-47a3-eae3-51255bda8413"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Collecting albumentations\n",
            "  Downloading albumentations-1.2.1-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.7.3)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 103 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Collecting qudida>=0.0.4\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (4.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
            "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-1.2.1 opencv-python-headless-4.6.0.66 qudida-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ],
      "metadata": {
        "id": "3I1m8nca22PV",
        "outputId": "66e921f1-e62a-4ae3-b131-73f0be72ff1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.6.0.66\n",
            "Uninstalling opencv-python-headless-4.6.0.66:\n",
            "  Successfully uninstalled opencv-python-headless-4.6.0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless==4.1.2.30"
      ],
      "metadata": {
        "id": "xniWyEqr24aV",
        "outputId": "8159d8e3-9677-4d2b-9e4b-9d46b6bcf5ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-headless==4.1.2.30\n",
            "  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.1.2.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries \n",
        "\n",
        "import os \n",
        "from pathlib import Path \n",
        "import xml.etree.ElementTree as ET \n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch \n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import numpy as np\n",
        "import cv2 \n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "CYTlPSvdy6U7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading the dataset"
      ],
      "metadata": {
        "id": "nWwPKHk4zBY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " %%bash\n",
        "\n",
        "wget \"https://public.roboflow.com/ds/kQQWZNGxGA?key=65kkvLv3xW\" -O data.zip \n",
        "\n",
        "unzip -q data.zip\n",
        "\n",
        "rm data.zip \n",
        "\n",
        "ls"
      ],
      "metadata": {
        "id": "CmJavTJTzIXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Transform "
      ],
      "metadata": {
        "id": "FABxjneCzOvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def transform\n",
        "def get_transform(train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.RandomCrop(height=300, width=300, p=0.5),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.RandomBrightness(p=0.5),\n",
        "            A.RandomContrast(p=0.5),\n",
        "            A.RandomGamma(p=0.5),\n",
        "            A.RandomRotate90(p=0.5),\n",
        "            A.PadIfNeeded(min_height=512, min_width=512, p=1),\n",
        "            A.Normalize(p=1, max_pixel_value=255.0, always_apply=True),\n",
        "            ToTensorV2(p=1.0)\n",
        "        ] , bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.PadIfNeeded(min_height=300, min_width=512, p=1),\n",
        "            A.Normalize(p=1, max_pixel_value=255.0, always_apply=True),\n",
        "            ToTensorV2(p=1.0)\n",
        "        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
      ],
      "metadata": {
        "id": "-5KdDdTP3LOV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskDetectionDataset(Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        self.root = Path(root)\n",
        "        self.transforms = transforms\n",
        "        self.image_paths = list(self.root.glob('*.jpg'))\n",
        "        self.image_paths.sort()\n",
        "        self.mask_paths = [p.parent / (p.stem + '.xml') for p in self.image_paths]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "        image = cv2.imread(str(image_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Parsing xml to get the labels and the bounding boxes\n",
        "        annotation = ET.parse(mask_path)\n",
        "        root = annotation.getroot()\n",
        "        objects = root.findall('object')\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for obj in objects:\n",
        "            name = obj.find('name').text\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = int(bbox.find('xmin').text)\n",
        "            ymin = int(bbox.find('ymin').text)\n",
        "            xmax = int(bbox.find('xmax').text)\n",
        "            ymax = int(bbox.find('ymax').text)\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(name)\n",
        "\n",
        "        # Converting the labels and the bounding boxes to tensors\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = list(map(lambda x: 1 if x == 'mask' else 0, labels))\n",
        "        labels = torch.as_tensor(labels)\n",
        "        image_id = torch.tensor([idx])\n",
        "\n",
        "        # Other parameters\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
        "\n",
        "        # Creating the tensor for the dataset\n",
        "        target = {}\n",
        "        target['boxes'] = boxes\n",
        "        target['labels'] = labels\n",
        "        target['image_id'] = image_id\n",
        "        target['area'] = area\n",
        "        target['iscrowd'] = iscrowd\n",
        "\n",
        "        # Applying the transforms\n",
        "        if self.transforms:\n",
        "            sample = self.transforms(image = image,\n",
        "                                     bboxes = target['boxes'],\n",
        "                                     labels = labels)\n",
        "            image = sample['image']\n",
        "            target['boxes'] = torch.Tensor(sample['bboxes'])\n",
        "\n",
        "        return image, target\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)"
      ],
      "metadata": {
        "id": "q0OlIiQc3Lma"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# these are the helper libraries imported.\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T"
      ],
      "metadata": {
        "id": "Kqu7ekEB3oWc",
        "outputId": "9b913f42-5630-4092-b04b-db739e2f2b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d2004cedcc81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# these are the helper libraries imported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'engine'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = MaskDetectionDataset('train', transforms= get_transform(train=True))\n",
        "train_dl = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0, collate_fn=utils.collate_fn)"
      ],
      "metadata": {
        "id": "tkjKMtqp3Osm",
        "outputId": "0acece3f-bf9b-4d6a-ca87-86eb2bcacb23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/albumentations/augmentations/transforms.py:1615: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/albumentations/augmentations/transforms.py:1641: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7d744e65b9a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskDetectionDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zopPQyGR3jNQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}