{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_Detection_Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJML3MiUO0BY4a8KMutKxN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skj092/Computer_Vision_Lab/blob/main/Mask_Detection_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57uDSFH8yyWn",
        "outputId": "f55a7e7a-89c5-4a12-86a3-48dbb9cb75d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 175725, done.\u001b[K\n",
            "remote: Counting objects: 100% (8088/8088), done.\u001b[K\n",
            "remote: Compressing objects: 100% (575/575), done.\u001b[K\n",
            "remote: Total 175725 (delta 7595), reused 7942 (delta 7496), pack-reused 167637\u001b[K\n",
            "Receiving objects: 100% (175725/175725), 348.80 MiB | 30.15 MiB/s, done.\n",
            "Resolving deltas: 100% (157200/157200), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "!pip install pycocotools --quiet\n",
        "!git clone https://github.com/pytorch/vision.git\n",
        "!git checkout v0.3.0\n",
        "\n",
        "!cp vision/references/detection/utils.py ./\n",
        "!cp vision/references/detection/transforms.py ./\n",
        "!cp vision/references/detection/coco_eval.py ./\n",
        "!cp vision/references/detection/engine.py ./\n",
        "!cp vision/references/detection/coco_utils.py ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U albumentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrx9ptEj0XkH",
        "outputId": "d678428e-cf96-446a-aeeb-8a0ffb31fd21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 116 kB 13.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 1.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "A.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E09gWluD0weA",
        "outputId": "d84248dd-ce54-4420-fe48-cddbd5cd6063"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.1.12'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries \n",
        "\n",
        "import os \n",
        "from pathlib import Path \n",
        "import xml.etree.ElementTree as ET \n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch \n",
        "import albumentations as A\n",
        "# from albumentations.pytorch.transforms import ToTensorV2\n",
        "import numpy as np\n",
        "import cv2 \n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "CYTlPSvdy6U7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading the dataset"
      ],
      "metadata": {
        "id": "nWwPKHk4zBY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CmJavTJTzIXC",
        "outputId": "b2521c10-17c9-452d-dbb7-03b3165dc13c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.1.12'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FABxjneCzOvK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}