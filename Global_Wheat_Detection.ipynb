{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Global-Wheat-Detection.ipynb",
      "provenance": [],
      "mount_file_id": "1aoc9zb0tnLUTzbkROpySm35Lj0QJdCAn",
      "authorship_tag": "ABX9TyPNy6ArMAhNsMUedxUW6J3y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skj092/Computer_Vision_Lab/blob/main/Global_Wheat_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_dir = \"/content/drive/MyDrive/ML\""
      ],
      "metadata": {
        "id": "LZRgVVsOXDUv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading the dataset"
      ],
      "metadata": {
        "id": "jfJEu8MoYKbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv kaggle.json /root/.kaggle/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkOhD5W8XHNG",
        "outputId": "06cd4673-1a8b-4065-b367-ee4813fe24d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW4JeXELXf8z",
        "outputId": "0f8bb9fe-aaa3-4cb1-ffd7-d9818553e3ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/ML/data"
      ],
      "metadata": {
        "id": "oCPwa6JfX-h7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ML/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7JWar0bYD5s",
        "outputId": "7379edb0-aea3-4300-ee9e-c861c13bf464"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c global-wheat-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NjspAlWXPmX",
        "outputId": "8ce44320-a003-4af2-fe9b-ce220326e49f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading global-wheat-detection.zip to /content/drive/MyDrive/ML/data\n",
            " 98% 593M/607M [00:04<00:00, 92.0MB/s]\n",
            "100% 607M/607M [00:04<00:00, 132MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip global-wheat-detection.zip"
      ],
      "metadata": {
        "id": "1epJcYWCYDE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm global-wheat-detection.zip"
      ],
      "metadata": {
        "id": "OEDkUugjYn_O"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jiYB2N73XRSa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Envieonment "
      ],
      "metadata": {
        "id": "1cwMW_MfXWWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycocotools --quiet\n",
        "!git clone https://github.com/pytorch/vision.git\n",
        "!git checkout v0.3.0\n",
        "\n",
        "!cp vision/references/detection/utils.py ./\n",
        "!cp vision/references/detection/transforms.py ./\n",
        "!cp vision/references/detection/coco_eval.py ./\n",
        "!cp vision/references/detection/engine.py ./\n",
        "!cp vision/references/detection/coco_utils.py ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKQis1GzY0Cb",
        "outputId": "29e285fd-6f69-4313-f6dc-13b3b8aba707"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 177820, done.\u001b[K\n",
            "remote: Counting objects: 100% (10205/10205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (634/634), done.\u001b[K\n",
            "remote: Total 177820 (delta 9612), reused 10083 (delta 9550), pack-reused 167615\u001b[K\n",
            "Receiving objects: 100% (177820/177820), 350.71 MiB | 31.25 MiB/s, done.\n",
            "Resolving deltas: 100% (159200/159200), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FfJbb4uY5qK",
        "outputId": "5f060c07-860a-4b08-dad9-907c9834f119"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless==4.1.2.30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMyWdBmHZPCR",
        "outputId": "14b97c68-6b7d-4cc0-cbe8-5ef19872949e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-headless==4.1.2.30\n",
            "  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.1.2.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/content/drive/MyDrive/ML\""
      ],
      "metadata": {
        "id": "GbRtnI7ga8Og"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries \n",
        "\n",
        "import os \n",
        "from pathlib import Path \n",
        "import xml.etree.ElementTree as ET \n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch \n",
        "import albumentations as A\n",
        "# from albumentations.pytorch.transforms import ToTensorV2\n",
        "import numpy as np\n",
        "import cv2 \n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torchvision\n",
        "import pandas as pd \n",
        "import ast\n",
        "\n",
        "# these are the helper libraries imported.\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "# import transforms as T"
      ],
      "metadata": {
        "id": "WK62dOYxZRSE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Transform"
      ],
      "metadata": {
        "id": "w0le6rhxZW85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    transforms.append(T.ToTensor())\n",
        "    if train:\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms)"
      ],
      "metadata": {
        "id": "zWpirhzQZeNq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and DataLoader"
      ],
      "metadata": {
        "id": "WMHM4VPfZkhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WheatDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        image_id, bboxes = self.df.iloc[idx]\n",
        "        image_path = os.path.join(self.image_dir, image_id+'.jpg')\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        boxes = []\n",
        "        for bbox in bboxes:\n",
        "            x1 = bbox[0]\n",
        "            y1 = bbox[1]\n",
        "            x2 = x1+bbox[2]\n",
        "            y2 = y1+bbox[3]\n",
        "            bbox = [x1, y1, x2, y2]\n",
        "            boxes.append(bbox)\n",
        "        labels = torch.ones((len(boxes),), dtype=torch.int64)\n",
        "        bboxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        target = {'boxes': bboxes, 'labels': labels}\n",
        "        return image, target"
      ],
      "metadata": {
        "id": "21wv-gpOZp99"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(root_dir, 'data/train.csv'))\n",
        "df['bbox'] = df['bbox'].apply(ast.literal_eval)\n",
        "df = df.groupby('image_id')['bbox'].apply(list).reset_index(name='bboxes')"
      ],
      "metadata": {
        "id": "UYgNHCNGZq1m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "o9mVQUNfZ4l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "def get_object_detection_model(num_classes):\n",
        "    # load a model pre-trained pre-trained on COCO\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "lEEcPvhzaX9L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing On One Batch"
      ],
      "metadata": {
        "id": "eIXKxuwDbNSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(root_dir, 'data/train')\n",
        "ds = WheatDataset(df, train_dir, transform=get_transform(train=True))\n",
        "dl = DataLoader(ds, batch_size=2, shuffle=True, collate_fn=utils.collate_fn)\n",
        "images,targets = next(iter(dl))\n",
        "images = list(image for image in images)\n",
        "targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "model = get_object_detection_model(2)\n",
        "predictions = model(images, targets)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HykXw6vfafQ-",
        "outputId": "c50b4a28-35c1-496d-83aa-e08d1e2a932b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss_box_reg': tensor(0.3618, grad_fn=<DivBackward0>),\n",
              " 'loss_classifier': tensor(0.8381, grad_fn=<NllLossBackward0>),\n",
              " 'loss_objectness': tensor(4.3046, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
              " 'loss_rpn_box_reg': tensor(0.1343, grad_fn=<DivBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sAqovDSHathT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}